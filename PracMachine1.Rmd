---
title: "Practical Machine Learning Project - Prediction Assignment"
author: "Simon Kong"
date: "Jan 10, 2016"
output: html_document
---
#Executive Summary
This report is made for the purposes of the Practical Machine Learning course offered by John Hopkins University through the Coursera platform. The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har.

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. 

In this project, We are given two datasets, the training and testing data set.The data is from accelerometers on the belt, forearm, arm, and dumbell of 6 research study participants. Our training data consists of accelerometer data and a label identifying the quality of the activity the participant was doing. Our testing data consists of accelerometer data without the identifying label. Our goal is to train the first data set by means of machine learning and make predictions in the second one. The trained variable is the way the exercises are being made and is a factor variable with five outcomes, A, B, C, D and E.


```{r, echo=FALSE}

library(knitr)
library(caret)
library(randomForest)
```
## Data Loading and Cleaning
To load the data and clean the data, the first row index and all colomuns with NA were removed. 
```{r}
# Read cleaned training and testing data 
workoutTraining <- read.csv("./pml-training.csv")
workoutTesting <- read.csv("./pml-testing.csv")
dim(workoutTraining)
sum(complete.cases(workoutTraining))
# we see that there are "X" and "user_name" columns which is not useful for creating model.
removeColums <- grep("X|user_name", names(workoutTraining))
workoutTraining <- workoutTraining[, -removeColums]
zeroVar <- nearZeroVar(workoutTraining)
workoutTraining <- workoutTraining[, -zeroVar]
NAs <- apply(workoutTraining, 2, function(x) {
    sum(is.na(x))
})

```


## Exploratory Data Analysis
Exploration done by doing a summary of the dataset. Around 100 variables have mostly NAs as values. 
```{r}
workoutTraining <- workoutTraining[, which(NAs == 0)]

```
## Prepare cross-validation data
Partition the original training data into 70% training and 30% test.

```{r}

dim(workoutTraining)
Index <- createDataPartition(y = workoutTraining$classe, p = 0.7, list = FALSE)
workoutTrainingSubTrain <- workoutTraining[Index, ]
workoutTrainingSubTest <- workoutTraining[-Index, ]

```

## Build random forest model with full training model
Chosen model is random forest which already has some built-in cross-validation function.
Cross Validation was performed to find the out of sample errors. 

```{r}
rfFit <- randomForest(classe ~ ., data = workoutTrainingSubTrain, importance = TRUE, ntrees = 10)
rfFit
# cross validation for Random Forests
pred <- predict(rfFit,workoutTrainingSubTest)
workoutTrainingSubTest$predRight <- pred==workoutTrainingSubTest$classe
table(pred,workoutTrainingSubTest$classe)

confusionMatrix(pred, workoutTrainingSubTest$classe)

```
Confusion matrix for test set vs model prediction shows good prediction across all 5 classes as well.Accuracy of the fit with the test set shows 99.85%, or an error of 0.15%.  
the Random Forests has much better accuracy then other models.

We get 99.85% accuracy on the train data.

## Write the Prediction to files
```{r}
# Function to write a vector to files
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_", i ,".txt")
    write.table(x[i], file = filename, quote = FALSE,
                row.names = FALSE, col.names = FALSE)
  }
}
# Call the function
#pml_write_files(PredictForest)

```


